{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "447baaed-7e3b-4d83-b2fb-df43b4e73d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import nibabel\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "935fea70-213d-49cc-a81b-809d27c86b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mask(aseg_image, brain_image, labels = [2, 41]):\n",
    "    from scipy.ndimage import zoom\n",
    "    brain_data = brain_image.get_fdata() \n",
    "    aseg_data = aseg_image.get_fdata() \n",
    "    brain_mask = np.zeros_like(aseg_data)\n",
    "    for label in labels:\n",
    "        brain_mask += np.where((aseg_data == label), 1, 0)\n",
    "\n",
    "    segmented_brain_image = brain_data * brain_mask #applied mask on the brain image\n",
    "#     resized_image = zoom(segmented_brain_image, np.array(target_size) / np.array(segmented_brain_image.shape), order=0)\n",
    "    segmented_brain_image = nibabel.Nifti1Image(segmented_brain_image, affine=None) # Generating the nii image\n",
    "    \n",
    "    return segmented_brain_image\n",
    "\n",
    "def resize_image(img_data):\n",
    "    resized_img_data = torch.nn.functional.interpolate(\n",
    "        torch.unsqueeze(torch.unsqueeze(torch.tensor(img_data), 0), 0),\n",
    "        size=(100, 100, 100),\n",
    "        mode='trilinear',\n",
    "        align_corners=False,\n",
    "    )\n",
    "    return resized_img_data.squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "343e08e5-071c-408c-b451-689242593ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"ADNI1_Screening_1.5T_1_29_2024.csv\"\n",
    "# base = \"/kaggle/input/adni-1-5t-fastsurfer-quickseg/ADNI-1.5T-FastSurfer-QuickSeg/\"\n",
    "mri_images = os.listdir(\"AD\")\n",
    "for i in os.listdir(\"CN\"):\n",
    "    mri_images.append(i)\n",
    "for i in os.listdir(\"MCI\"):\n",
    "    mri_images.append(i)\n",
    "    \n",
    "csv_data = pd.read_csv(csv_path)\n",
    "df = pd.DataFrame(csv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c97bdead-7f85-4f09-9a5b-59be95fe1d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    file_name = row['Image Data ID'] + \".nii\"\n",
    "    if file_name not in mri_images:\n",
    "        df = df.drop(index)\n",
    "df.to_csv(\"filter_csv.csv\")\n",
    "csv_path = \"filter.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baac1753-83ea-415b-a6a7-cc07f68f4210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(982, 982)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df), len(mri_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbe38d57-3b82-4767-af33-933bc5862d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Data ID</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Group</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Visit</th>\n",
       "      <th>Modality</th>\n",
       "      <th>Description</th>\n",
       "      <th>Type</th>\n",
       "      <th>Acq Date</th>\n",
       "      <th>Format</th>\n",
       "      <th>Downloaded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I62666</td>\n",
       "      <td>013_S_1275</td>\n",
       "      <td>MCI</td>\n",
       "      <td>F</td>\n",
       "      <td>79</td>\n",
       "      <td>sc</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; GradWarp; B1 Correction; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>2/22/2007</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>1/29/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I119268</td>\n",
       "      <td>121_S_1322</td>\n",
       "      <td>MCI</td>\n",
       "      <td>F</td>\n",
       "      <td>72</td>\n",
       "      <td>sc</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; ; N3; Scaled_2</td>\n",
       "      <td>Processed</td>\n",
       "      <td>3/02/2007</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>1/29/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I59697</td>\n",
       "      <td>116_S_0649</td>\n",
       "      <td>MCI</td>\n",
       "      <td>M</td>\n",
       "      <td>87</td>\n",
       "      <td>sc</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; GradWarp; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>7/24/2006</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>1/29/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I68581</td>\n",
       "      <td>099_S_0880</td>\n",
       "      <td>MCI</td>\n",
       "      <td>M</td>\n",
       "      <td>84</td>\n",
       "      <td>sc</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; GradWarp; B1 Correction; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>10/05/2006</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>1/29/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I60760</td>\n",
       "      <td>029_S_1318</td>\n",
       "      <td>MCI</td>\n",
       "      <td>F</td>\n",
       "      <td>83</td>\n",
       "      <td>sc</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR-R; GradWarp; B1 Correction; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>2/17/2007</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>1/29/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I62656</td>\n",
       "      <td>013_S_1186</td>\n",
       "      <td>MCI</td>\n",
       "      <td>M</td>\n",
       "      <td>83</td>\n",
       "      <td>sc</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; GradWarp; B1 Correction; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>1/29/2007</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>1/29/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I119369</td>\n",
       "      <td>128_S_0188</td>\n",
       "      <td>MCI</td>\n",
       "      <td>M</td>\n",
       "      <td>86</td>\n",
       "      <td>sc</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR-R; GradWarp; N3; Scaled_2</td>\n",
       "      <td>Processed</td>\n",
       "      <td>2/06/2006</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>1/29/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I31509</td>\n",
       "      <td>023_S_0855</td>\n",
       "      <td>MCI</td>\n",
       "      <td>M</td>\n",
       "      <td>76</td>\n",
       "      <td>sc</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; GradWarp; B1 Correction; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>9/05/2006</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>1/29/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I63135</td>\n",
       "      <td>073_S_1357</td>\n",
       "      <td>MCI</td>\n",
       "      <td>M</td>\n",
       "      <td>71</td>\n",
       "      <td>sc</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; GradWarp; B1 Correction; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>4/09/2007</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>1/29/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I39152</td>\n",
       "      <td>130_S_0783</td>\n",
       "      <td>MCI</td>\n",
       "      <td>F</td>\n",
       "      <td>79</td>\n",
       "      <td>sc</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; GradWarp; B1 Correction; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>8/17/2006</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>1/29/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I118769</td>\n",
       "      <td>018_S_0406</td>\n",
       "      <td>MCI</td>\n",
       "      <td>M</td>\n",
       "      <td>78</td>\n",
       "      <td>sc</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; ; N3; Scaled_2</td>\n",
       "      <td>Processed</td>\n",
       "      <td>4/20/2006</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>1/29/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I69733</td>\n",
       "      <td>129_S_1246</td>\n",
       "      <td>MCI</td>\n",
       "      <td>M</td>\n",
       "      <td>72</td>\n",
       "      <td>sc</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; GradWarp; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>2/06/2007</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>1/29/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I48851</td>\n",
       "      <td>023_S_1104</td>\n",
       "      <td>MCI</td>\n",
       "      <td>F</td>\n",
       "      <td>65</td>\n",
       "      <td>sc</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR-R; GradWarp; B1 Correction; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>11/15/2006</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>1/29/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I119534</td>\n",
       "      <td>133_S_0727</td>\n",
       "      <td>MCI</td>\n",
       "      <td>F</td>\n",
       "      <td>69</td>\n",
       "      <td>sc</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR-R; GradWarp; B1 Correction; N3; Scaled_2</td>\n",
       "      <td>Processed</td>\n",
       "      <td>9/07/2006</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>1/29/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I75485</td>\n",
       "      <td>073_S_0909</td>\n",
       "      <td>MCI</td>\n",
       "      <td>F</td>\n",
       "      <td>69</td>\n",
       "      <td>sc</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; GradWarp; B1 Correction; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>10/02/2006</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>1/29/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>I49757</td>\n",
       "      <td>114_S_1103</td>\n",
       "      <td>MCI</td>\n",
       "      <td>M</td>\n",
       "      <td>83</td>\n",
       "      <td>sc</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; GradWarp; B1 Correction; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>11/29/2006</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>1/29/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I118975</td>\n",
       "      <td>023_S_0331</td>\n",
       "      <td>MCI</td>\n",
       "      <td>F</td>\n",
       "      <td>65</td>\n",
       "      <td>sc</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; GradWarp; B1 Correction; N3; Scaled_2</td>\n",
       "      <td>Processed</td>\n",
       "      <td>3/23/2006</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>1/29/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>I80161</td>\n",
       "      <td>041_S_1411</td>\n",
       "      <td>MCI</td>\n",
       "      <td>M</td>\n",
       "      <td>74</td>\n",
       "      <td>sc</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; GradWarp; B1 Correction; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>7/16/2007</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>1/29/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>I40037</td>\n",
       "      <td>041_S_0598</td>\n",
       "      <td>MCI</td>\n",
       "      <td>M</td>\n",
       "      <td>72</td>\n",
       "      <td>sc</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; GradWarp; B1 Correction; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>6/16/2006</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>1/29/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>I119071</td>\n",
       "      <td>027_S_0179</td>\n",
       "      <td>MCI</td>\n",
       "      <td>M</td>\n",
       "      <td>81</td>\n",
       "      <td>sc</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR-R; GradWarp; B1 Correction; N3; Scaled_2</td>\n",
       "      <td>Processed</td>\n",
       "      <td>2/24/2006</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>1/29/2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Image Data ID     Subject Group Sex  Age Visit Modality  \\\n",
       "0         I62666  013_S_1275   MCI   F   79    sc      MRI   \n",
       "1        I119268  121_S_1322   MCI   F   72    sc      MRI   \n",
       "2         I59697  116_S_0649   MCI   M   87    sc      MRI   \n",
       "3         I68581  099_S_0880   MCI   M   84    sc      MRI   \n",
       "4         I60760  029_S_1318   MCI   F   83    sc      MRI   \n",
       "5         I62656  013_S_1186   MCI   M   83    sc      MRI   \n",
       "6        I119369  128_S_0188   MCI   M   86    sc      MRI   \n",
       "7         I31509  023_S_0855   MCI   M   76    sc      MRI   \n",
       "8         I63135  073_S_1357   MCI   M   71    sc      MRI   \n",
       "9         I39152  130_S_0783   MCI   F   79    sc      MRI   \n",
       "10       I118769  018_S_0406   MCI   M   78    sc      MRI   \n",
       "11        I69733  129_S_1246   MCI   M   72    sc      MRI   \n",
       "12        I48851  023_S_1104   MCI   F   65    sc      MRI   \n",
       "13       I119534  133_S_0727   MCI   F   69    sc      MRI   \n",
       "14        I75485  073_S_0909   MCI   F   69    sc      MRI   \n",
       "15        I49757  114_S_1103   MCI   M   83    sc      MRI   \n",
       "16       I118975  023_S_0331   MCI   F   65    sc      MRI   \n",
       "17        I80161  041_S_1411   MCI   M   74    sc      MRI   \n",
       "18        I40037  041_S_0598   MCI   M   72    sc      MRI   \n",
       "19       I119071  027_S_0179   MCI   M   81    sc      MRI   \n",
       "\n",
       "                                     Description       Type    Acq Date  \\\n",
       "0       MPR; GradWarp; B1 Correction; N3; Scaled  Processed   2/22/2007   \n",
       "1                            MPR; ; N3; Scaled_2  Processed   3/02/2007   \n",
       "2                      MPR; GradWarp; N3; Scaled  Processed   7/24/2006   \n",
       "3       MPR; GradWarp; B1 Correction; N3; Scaled  Processed  10/05/2006   \n",
       "4     MPR-R; GradWarp; B1 Correction; N3; Scaled  Processed   2/17/2007   \n",
       "5       MPR; GradWarp; B1 Correction; N3; Scaled  Processed   1/29/2007   \n",
       "6                  MPR-R; GradWarp; N3; Scaled_2  Processed   2/06/2006   \n",
       "7       MPR; GradWarp; B1 Correction; N3; Scaled  Processed   9/05/2006   \n",
       "8       MPR; GradWarp; B1 Correction; N3; Scaled  Processed   4/09/2007   \n",
       "9       MPR; GradWarp; B1 Correction; N3; Scaled  Processed   8/17/2006   \n",
       "10                           MPR; ; N3; Scaled_2  Processed   4/20/2006   \n",
       "11                     MPR; GradWarp; N3; Scaled  Processed   2/06/2007   \n",
       "12    MPR-R; GradWarp; B1 Correction; N3; Scaled  Processed  11/15/2006   \n",
       "13  MPR-R; GradWarp; B1 Correction; N3; Scaled_2  Processed   9/07/2006   \n",
       "14      MPR; GradWarp; B1 Correction; N3; Scaled  Processed  10/02/2006   \n",
       "15      MPR; GradWarp; B1 Correction; N3; Scaled  Processed  11/29/2006   \n",
       "16    MPR; GradWarp; B1 Correction; N3; Scaled_2  Processed   3/23/2006   \n",
       "17      MPR; GradWarp; B1 Correction; N3; Scaled  Processed   7/16/2007   \n",
       "18      MPR; GradWarp; B1 Correction; N3; Scaled  Processed   6/16/2006   \n",
       "19  MPR-R; GradWarp; B1 Correction; N3; Scaled_2  Processed   2/24/2006   \n",
       "\n",
       "   Format Downloaded  \n",
       "0   NiFTI  1/29/2024  \n",
       "1   NiFTI  1/29/2024  \n",
       "2   NiFTI  1/29/2024  \n",
       "3   NiFTI  1/29/2024  \n",
       "4   NiFTI  1/29/2024  \n",
       "5   NiFTI  1/29/2024  \n",
       "6   NiFTI  1/29/2024  \n",
       "7   NiFTI  1/29/2024  \n",
       "8   NiFTI  1/29/2024  \n",
       "9   NiFTI  1/29/2024  \n",
       "10  NiFTI  1/29/2024  \n",
       "11  NiFTI  1/29/2024  \n",
       "12  NiFTI  1/29/2024  \n",
       "13  NiFTI  1/29/2024  \n",
       "14  NiFTI  1/29/2024  \n",
       "15  NiFTI  1/29/2024  \n",
       "16  NiFTI  1/29/2024  \n",
       "17  NiFTI  1/29/2024  \n",
       "18  NiFTI  1/29/2024  \n",
       "19  NiFTI  1/29/2024  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d64d252-d9fb-4c05-be95-705ced241385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the 3D ResNet model\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=3):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Conv3d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv3d(self.inplanes, planes * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm3d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Basic block for 3D ResNet\n",
    "class Block(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Block, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(inplanes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv3d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "def resnet18():\n",
    "    return ResNet(Block, [2, 2, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a14ff30-2bb4-4617-ae57-64f55cc57300",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MriDataset():\n",
    "    def __init__(self, csv_path,transform=None):\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.transform = transform\n",
    "        self.le = LabelEncoder()  # Add this line\n",
    "        self.encoded_classes = self.le.fit_transform(self.data[\"Group\"].values)  # Add this line\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _load_image(self, img_id, label):\n",
    "        base = \"/kaggle/input/adni-1-5t-fastsurfer-quickseg/ADNI-1.5T-FastSurfer-QuickSeg\"\n",
    "        img_id = img_id + \".nii\"\n",
    "        subject_dir = os.path.join(label, img_id, \"mri\")\n",
    "        \n",
    "        aseg_image = nibabel.load(os.path.join(subject_dir, \"aparc.DKTatlas+aseg.deep.mgz\"))\n",
    "        brain_image = nibabel.load(os.path.join(subject_dir, \"aparc.DKTatlas+aseg.deep.mgz\"))\n",
    "        \n",
    "        image = apply_mask(aseg_image, brain_image) #applying the selected labels\n",
    "        image = image.get_fdata()\n",
    "        \n",
    "        image_resized = resize_image(image) \n",
    "        image_resized = np.expand_dims(image_resized, axis=0)\n",
    "        image_resized = torch.tensor(image_resized, dtype=torch.float)\n",
    "        \n",
    "        return image_resized\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.data.iloc[idx, 1]\n",
    "        label = self.data.iloc[idx, 3]\n",
    "        \n",
    "        img = self._load_image(img_id, label) #loading the image\n",
    "        one_hot_label = np.eye(len(self.le.classes_))[self.encoded_classes[idx]]\n",
    "        \n",
    "        #img = np.transpose(img, (2, 0, 1))    # Transpose the image to match PyTorch's tensor format (C x H x W)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, one_hot_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e86a84ac-20dd-459d-b2c3-80add3d1524d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = MriDataset(csv_path=\"filter_csv.csv\", transform=transform)\n",
    "train_size = int(0.7 * len(dataset))\n",
    "validation_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset)-(train_size + validation_size)\n",
    "\n",
    "train_dataset, validation_dataset, test_dataset = random_split(dataset, [train_size, validation_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a840c72-ea2c-4978-bf7b-61511fcd9d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(687, 147, 148)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size, validation_size, test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ad7cbe4-a3ab-4840-ac0d-3c92092df705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True, pin_memory = True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size = 20, shuffle=True, pin_memory = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 20, shuffle=True, pin_memory = True)\n",
    "\n",
    "\n",
    "#model\n",
    "model = resnet18()\n",
    "# model = models.resnet18(pretrained = True)\n",
    "\n",
    "# model.conv1 = nn.Conv2d(150, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "# model.fc = nn.Linear(512, 3)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ac86868-1e7f-4f37-ba6b-fb15b08d70d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchsummaryNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\n",
      "Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "Installing collected packages: torchsummary\n",
      "Successfully installed torchsummary-1.5.1\n"
     ]
    }
   ],
   "source": [
    "pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58bf0a8f-d14f-4945-abbc-49c65f8cd5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           6,272\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
      "             ReLU-21          [-1, 128, 28, 28]               0\n",
      "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
      "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
      "             ReLU-26          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
      "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
      "             ReLU-30          [-1, 128, 28, 28]               0\n",
      "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
      "             ReLU-37          [-1, 256, 14, 14]               0\n",
      "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
      "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
      "             ReLU-42          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
      "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
      "             ReLU-46          [-1, 256, 14, 14]               0\n",
      "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
      "             ReLU-49          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
      "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-53            [-1, 512, 7, 7]               0\n",
      "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-58            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
      "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-62            [-1, 512, 7, 7]               0\n",
      "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-65            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                 [-1, 1000]         513,000\n",
      "================================================================\n",
      "Total params: 11,686,376\n",
      "Trainable params: 11,686,376\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.38\n",
      "Forward/backward pass size (MB): 62.79\n",
      "Params size (MB): 44.58\n",
      "Estimated Total Size (MB): 107.76\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6794946-fc89-4328-a4e3-73e43544c63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"checkpoint\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a4d1616-dc17-407d-ac58-455210f3d18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA can not be found, using CPU instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|                                                                                 | 0/1 [00:00<?, ?epoch/s]\n",
      "Epoch 1: 0batch [00:00, ?batch/s]\u001b[A\n",
      "Epoch 1: 1batch [00:27, 27.61s/batch]\u001b[A\n",
      "Epoch 1: 2batch [00:54, 27.13s/batch]\u001b[A\n",
      "Epoch 1: 3batch [01:20, 26.53s/batch]\u001b[A\n",
      "Epoch 1: 4batch [01:45, 26.11s/batch]\u001b[A\n",
      "Epoch 1: 5batch [02:11, 26.10s/batch]\u001b[A\n",
      "Epoch 1: 6batch [02:36, 25.78s/batch]\u001b[A\n",
      "Epoch 1: 7batch [03:02, 25.71s/batch]\u001b[A\n",
      "Epoch 1: 8batch [03:28, 25.89s/batch]\u001b[A\n",
      "Epoch 1: 9batch [03:56, 26.34s/batch]\u001b[A\n",
      "Epoch 1: 10batch [04:22, 26.28s/batch]\u001b[A\n",
      "Epoch 1: 11batch [04:48, 26.16s/batch]\u001b[A\n",
      "Epoch 1: 12batch [05:13, 26.06s/batch]\u001b[A\n",
      "Epoch 1: 13batch [05:40, 26.19s/batch]\u001b[A\n",
      "Epoch 1: 14batch [06:06, 26.27s/batch]\u001b[A\n",
      "Epoch 1: 15batch [06:32, 26.06s/batch]\u001b[A\n",
      "Epoch 1: 16batch [06:58, 25.97s/batch]\u001b[A\n",
      "Epoch 1: 17batch [07:23, 25.66s/batch]\u001b[A\n",
      "Epoch 1: 18batch [07:49, 25.71s/batch]\u001b[A\n",
      "Epoch 1: 19batch [08:14, 25.66s/batch]\u001b[A\n",
      "Epoch 1: 20batch [08:41, 25.91s/batch]\u001b[A\n",
      "Epoch 1: 21batch [09:07, 25.97s/batch]\u001b[A\n",
      "Epoch 1: 22batch [09:33, 25.98s/batch]\u001b[A\n",
      "Epoch 1: 23batch [09:59, 26.07s/batch]\u001b[A\n",
      "Epoch 1: 24batch [10:25, 26.11s/batch]\u001b[A\n",
      "Epoch 1: 25batch [10:51, 26.02s/batch]\u001b[A\n",
      "Epoch 1: 26batch [11:17, 25.97s/batch]\u001b[A\n",
      "Epoch 1: 27batch [11:43, 26.17s/batch]\u001b[A\n",
      "Epoch 1: 28batch [12:10, 26.16s/batch]\u001b[A\n",
      "Epoch 1: 29batch [12:36, 26.10s/batch]\u001b[A\n",
      "Epoch 1: 30batch [13:02, 26.07s/batch]\u001b[A\n",
      "Epoch 1: 31batch [13:27, 26.03s/batch]\u001b[A\n",
      "Epoch 1: 32batch [13:53, 26.01s/batch]\u001b[A\n",
      "Epoch 1: 33batch [14:19, 25.95s/batch]\u001b[A\n",
      "Epoch 1: 34batch [14:45, 25.89s/batch]\u001b[A\n",
      "Epoch 1: 35batch [14:55, 21.11s/batch]\u001b[A\n",
      "Epochs: 100%|████████████████████████████████████████████████████████████████████████| 1/1 [14:55<00:00, 895.49s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1, Loss: 1.0130, Accuracy: 42.9403%\n",
      "Final model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm  # Import tqdm for progress tracking\n",
    "\n",
    "# Set the device only once and use it throughout; no need to check every time\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"Using {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CUDA can not be found, using CPU instead.\")\n",
    "\n",
    "num_epochs = 1  # number of epochs\n",
    "loss_list = []  # To store loss after each epoch\n",
    "accuracy_list = []  # To store accuracy after each epoch\n",
    "\n",
    "# Move the model to the device once instead of inside the loop\n",
    "model.to(device)\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), desc=\"Epochs\", unit=\"epoch\"):\n",
    "    torch.cuda.empty_cache()  # Clear CUDA cache to free memory\n",
    "    \n",
    "    model.train()  # Set the model to training mode\n",
    "    total = 0\n",
    "    correct_count = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in tqdm(enumerate(train_loader), desc=f\"Epoch {epoch + 1}\", unit=\"batch\", leave=False):\n",
    "        # for batch_idx, data in tqdm(enumerate(dataloader), desc=f\"Epoch {epoch + 1}\", unit=\"batch\", leave=False):\n",
    "        data, target = data.to(device, dtype=torch.float), target.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        \n",
    "        # Adjust target shape if necessary (See Note below)\n",
    "        if target.ndim > 1 and target.size(1) > 1:  # Case for one-hot encoded targets\n",
    "            target = torch.argmax(target, dim=1)\n",
    "        elif target.ndim > 1 and target.size(1) == 1:  # Case for extra singleton dimension\n",
    "            target = target.squeeze()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        correct = (torch.argmax(output, dim=1) == target).sum().item()\n",
    "        correct_count += correct\n",
    "        total += target.size(0)\n",
    "    \n",
    "    # Log the epoch's results\n",
    "    accuracy = (correct_count / total) * 100\n",
    "    loss_list.append(loss.item())\n",
    "    accuracy_list.append(accuracy)\n",
    "    print(f\"Epoch: {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}, Accuracy: {accuracy:.4f}%\")\n",
    "    \n",
    "    # # Save checkpoints at specified intervals\n",
    "    # if (epoch + 1) % 5 == 0:stat_result = os.stat(filename)\n",
    "    #     checkpoint_dir = \"checkpoint_dir\"  # We need to make sure this directory exists or create it\n",
    "    #     if not os.path.exists(checkpoint_dir):\n",
    "    #         os.makedirs(checkpoint_dir)\n",
    "    #     checkpoint_path = os.path.join(checkpoint_dir, f\"model_epoch_{epoch+1}.pt\")\n",
    "    #     torch.save({\n",
    "    #         'epoch': epoch + 1,\n",
    "    #         'model_state_dict': model.state_dict(),\n",
    "    #         'optimizer_state_dict': optimizer.state_dict(),\n",
    "    #         'loss': loss.item(),\n",
    "    #     }, checkpoint_path)\n",
    "    #     print(f\"Checkpoint saved to {checkpoint_path}\")\n",
    "    \n",
    "# Save the final model\n",
    "# torch.save(model.state_dict(), \"model_final.pt\")\n",
    "print(\"Final model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "497a03a9-7f8b-4242-8084-926520bba758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Training Accuracy')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, (loss_graph, accuracy_graph) = plt.subplots(1, 2, figsize=(12,6))\n",
    "\n",
    "loss_graph.plot(loss_list)\n",
    "loss_graph.set_xlabel(\"Epoch\")\n",
    "loss_graph.set_ylabel(\"Loss\")\n",
    "loss_graph.set_title(\"Training Loss\")\n",
    "\n",
    "accuracy_graph.plot(accuracy_list)\n",
    "accuracy_graph.set_xlabel(\"Epoch\")\n",
    "accuracy_graph.set_ylabel(\"Loss\")\n",
    "accuracy_graph.set_title(\"Training Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f067fb9d-8ead-421a-a295-42c7af580935",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\simra\\AppData\\Local\\Temp\\ipykernel_10616\\318942741.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data, target = data.to(device, dtype = torch.float), torch.tensor(target).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 47.62%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for data, target in validation_loader:\n",
    "        model = model.to(device)\n",
    "        data, target = data.to(device, dtype = torch.float), torch.tensor(target).to(device)\n",
    "        output = model(data)\n",
    "        output = output.cpu()\n",
    "        target = target.cpu()\n",
    "        \n",
    "        all_preds.extend(torch.argmax(output, dim = 1))\n",
    "        all_labels.extend(torch.argmax(target, dim=1))\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f\"Validation accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "160a3178-2f6a-4be6-990d-727e7e77d52f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or no access: 'MCI/I34837.nii/mri/aparc.DKTatlas+aseg.deep.mgz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nibabel\\loadsave.py:101\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, **kwargs)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 101\u001b[0m     stat_result \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstat(filename)\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'MCI/I34837.nii/mri/aparc.DKTatlas+aseg.deep.mgz'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m test_labels_probs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data, target \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[0;32m      8\u001b[0m         model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      9\u001b[0m         data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat), torch\u001b[38;5;241m.\u001b[39mtensor(target)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[1;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:420\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "Cell \u001b[1;32mIn[8], line 33\u001b[0m, in \u001b[0;36mMriDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     30\u001b[0m img_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39miloc[idx, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     31\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39miloc[idx, \u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m---> 33\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_image(img_id, label) \u001b[38;5;66;03m#loading the image\u001b[39;00m\n\u001b[0;32m     34\u001b[0m one_hot_label \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39meye(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mle\u001b[38;5;241m.\u001b[39mclasses_))[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoded_classes[idx]]\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m#img = np.transpose(img, (2, 0, 1))    # Transpose the image to match PyTorch's tensor format (C x H x W)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 17\u001b[0m, in \u001b[0;36mMriDataset._load_image\u001b[1;34m(self, img_id, label)\u001b[0m\n\u001b[0;32m     14\u001b[0m img_id \u001b[38;5;241m=\u001b[39m img_id \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.nii\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     15\u001b[0m subject_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(label, img_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmri\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m aseg_image \u001b[38;5;241m=\u001b[39m nibabel\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(subject_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maparc.DKTatlas+aseg.deep.mgz\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     18\u001b[0m brain_image \u001b[38;5;241m=\u001b[39m nibabel\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(subject_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maparc.DKTatlas+aseg.deep.mgz\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     20\u001b[0m image \u001b[38;5;241m=\u001b[39m apply_mask(aseg_image, brain_image) \u001b[38;5;66;03m#applying the selected labels\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nibabel\\loadsave.py:103\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m     stat_result \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstat(filename)\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m--> 103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or no access: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stat_result\u001b[38;5;241m.\u001b[39mst_size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ImageFileError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmpty file: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No such file or no access: 'MCI/I34837.nii/mri/aparc.DKTatlas+aseg.deep.mgz'"
     ]
    }
   ],
   "source": [
    "given the following data:\n",
    "model.eval()\n",
    "test_preds = []\n",
    "test_labels = []\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        model = model.to(device)\n",
    "        data, target = data.to(device, dtype = torch.float), torch.tensor(target).to(device)\n",
    "        output = model(data)\n",
    "        output = output.cpu()\n",
    "        target = target.cpu()\n",
    "        \n",
    "        test_preds.extend(torch.argmax(output, dim = 1))\n",
    "        test_labels.extend(torch.argmax(target, dim=1))\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f\"Test accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edf91406-2614-4738-be8a-b199f6ddb06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 52.70%\n",
      "Precision: 0.28\n",
      "F1 Score: 0.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\simra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [148, 8]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 38\u001b[0m\n\u001b[0;32m     36\u001b[0m     test_labels_one_hot \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39meye(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(test_labels)))[test_labels]  \u001b[38;5;66;03m# One-hot encoding\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     output_probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(output\u001b[38;5;241m.\u001b[39mcpu(), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m---> 38\u001b[0m     auc_roc \u001b[38;5;241m=\u001b[39m roc_auc_score(test_labels_one_hot, output_probs, multi_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m     output_probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(output\u001b[38;5;241m.\u001b[39mcpu(), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:648\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _average_binary_score(\n\u001b[0;32m    641\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[38;5;241m=\u001b[39mmax_fpr),\n\u001b[0;32m    642\u001b[0m         y_true,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    645\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    646\u001b[0m     )\n\u001b[0;32m    647\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# multilabel-indicator\u001b[39;00m\n\u001b[1;32m--> 648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _average_binary_score(\n\u001b[0;32m    649\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[38;5;241m=\u001b[39mmax_fpr),\n\u001b[0;32m    650\u001b[0m         y_true,\n\u001b[0;32m    651\u001b[0m         y_score,\n\u001b[0;32m    652\u001b[0m         average,\n\u001b[0;32m    653\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    654\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_base.py:77\u001b[0m, in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m binary_metric(y_true, y_score, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[1;32m---> 77\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[0;32m     78\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true)\n\u001b[0;32m     79\u001b[0m y_score \u001b[38;5;241m=\u001b[39m check_array(y_score)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [148, 8]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, f1_score, roc_auc_score, accuracy_score\n",
    "\n",
    "model.eval()\n",
    "test_preds = []\n",
    "test_labels = []\n",
    "\n",
    "# Ensure evaluation without gradient calculation\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        # Move data and model to device\n",
    "        model = model.to(device)\n",
    "        data, target = data.to(device, dtype=torch.float), target.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(data)\n",
    "        \n",
    "        # Collect predictions and true labels\n",
    "        test_preds.extend(torch.argmax(output.cpu(), dim=1).numpy())\n",
    "        test_labels.extend(torch.argmax(target.cpu(), dim=1).numpy())\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = accuracy_score(test_labels, test_preds)\n",
    "print(f\"Test accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Compute precision\n",
    "precision = precision_score(test_labels, test_preds, average='weighted')  # 'weighted' for multi-class tasks\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "\n",
    "# Compute F1 score\n",
    "f1 = f1_score(test_labels, test_preds, average='weighted')  # Adjust 'average' as needed\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# Compute AUC-ROC\n",
    "# For multi-class problems, provide one-hot encoding of test_labels and test_preds probabilities\n",
    "if len(set(test_labels)) > 2:  # Check if multi-class\n",
    "    test_labels_one_hot = np.eye(len(set(test_labels)))[test_labels]  # One-hot encoding\n",
    "    output_probs = torch.nn.functional.softmax(output.cpu(), dim=1).numpy()\n",
    "    auc_roc = roc_auc_score(test_labels_one_hot, output_probs, multi_class=\"ovr\")\n",
    "else:\n",
    "    output_probs = torch.nn.functional.softmax(output.cpu(), dim=1)[:, 1].numpy()\n",
    "    auc_roc = roc_auc_score(test_labels, output_probs)\n",
    "\n",
    "print(f\"AUC-ROC: {auc_roc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2683fdf-b478-48aa-9235-1fc1f6c576f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_probs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(test_labels)) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:  \u001b[38;5;66;03m# Multi-class case\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     test_labels_one_hot \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39meye(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(test_labels)))[test_labels]  \u001b[38;5;66;03m# One-hot encoding\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     auc_roc \u001b[38;5;241m=\u001b[39m roc_auc_score(test_labels_one_hot, np\u001b[38;5;241m.\u001b[39marray(all_probs), multi_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Binary classification case\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     auc_roc \u001b[38;5;241m=\u001b[39m roc_auc_score(test_labels, np\u001b[38;5;241m.\u001b[39marray(all_probs)[:, \u001b[38;5;241m1\u001b[39m])  \u001b[38;5;66;03m# Use positive class probabilities\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'all_probs' is not defined"
     ]
    }
   ],
   "source": [
    "# Compute AUC-ROC\n",
    "if len(set(test_labels)) > 2:  # Multi-class case\n",
    "    test_labels_one_hot = np.eye(len(set(test_labels)))[test_labels]  # One-hot encoding\n",
    "    auc_roc = roc_auc_score(test_labels_one_hot, np.array(all_probs), multi_class=\"ovr\")\n",
    "else:  # Binary classification case\n",
    "    auc_roc = roc_auc_score(test_labels, np.array(all_probs)[:, 1])  # Use positive class probabilities\n",
    "\n",
    "print(f\"AUC-ROC: {auc_roc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f33a2c-569b-45aa-9ec8-f324ccabb1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "import torch.nn as nn\n",
    "\n",
    "# Load and modify the model\n",
    "model = resnet18()\n",
    "model.conv1 = nn.Conv2d(2, 64, kernel_size=7, stride=2, padding=3, bias=False)  # Modify for 2 input channels\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Display the summary\n",
    "summary(model, input_size=(2, 224, 224))  # Adjust input size to match your data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
